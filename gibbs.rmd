---
#runtime: shiny
title: "Gibsov metod biranja uzorka - Gibbs sampling"
output:
  html_notebook: default
  html_document: default
---
***

**Gibsov metod biranja uzorka je jedan od MCMC metoda biranja uzorka iz aposteriorne raspodele.**

**MCMC** (Markov chain Monte Carlo) metod biranja uzorka obezbe?uje biranje uzorka iz
vi?edimenzionih gustina raspodela, razla?u?i ih na raspodele manjih dimenzija sa kojima je
lak?e raditi. Deo imena ?Monte Carlo", navedenog metoda, ukazuje na proces slu?ajne
simulacije, dok deo imena ?Markov chain" ukazuje da se element uzorka iz aposteriorne
raspodele bira na osnovu prethodno izabranog elementa. 

Gibsov metod podrazumeva biranje uzorka iz uslovne raspodele za svaki parametar posebno, uzimaju?i u obzir teku?e vrednosti svih ostalih parametara. 

Multivarijaciona = vi?e parametra raspodele.

Gibsov metod je naj?e??e kori??en MCMC metod u Bajesovoj statistici i opisan je na slede?i na?in: 

1. Dodeli $X^i_j$ neku vrednost $P$, gde je $i = 0$, $j = 0...k$
2. $i=i+1$
3. za svako $i$ manje od $n$
   izaberi \[ X^{(i)}_j \sim f(X^{(i)}_j | X^{(i)}_0,..., X^{(i)}_{j-1} ~,X^{(i-1)}_{j+1},...,X^{(i-1)}_k) \]

Ovo je op?ta ideja.

****
#### Pseudokod za biranje uzoraka iz dvodimenzionih gustina raspodela:
****

Ulaz: neophodni parametri za ra?unanje uslovnih verovatno?a <br/>
Izlaz: niz ta?aka koje su uzorci aposteriorne raspodele <br/>
  *inicijalizacija* $X^{(1)} = P$ <br/>
  $i = 2$ <br/>
  *za svako i manje od n radi:* <br/>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$Y^{(i)} \sim f(Y^{(i)} | X^{(i-1)})$ <br/>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$X^{(i)} \sim f(X^{(i)} | Y^{(i)})$ <br/>
  *izbri?i (eng. "burn-in") po?etnih S uzoraka u X i Y* <br/>
  *iscrtaj ?eljene grafi?ke prikaze* <br/>


Ukoliko bismo imali raspodelu sa vi?e od dva parametra, algoritam bi bio vrlo sli?an.

****
#### Pseudokod za biranje uzoraka iz vi?edimenzionih gustina raspodela:
****

Ulaz i izlaz isti kao i kod prethodnog algoritma.
<br/>
*Inicijalizuj* $X^{(1)}_k = P$, za $k = 1...j$ <br/>
$i = 2$<br/>
Za svako $i$ manje od $n$ radi:<br/>
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$X^{(i)}_1 \sim f(X^{(i)}_1| X^{(i-1)}_2, X^{(i-1)}_3,...,X^{(i-1)}_j)$<br/>
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$X^{(i)}_2 = f(X^{(i)}_2| X^{(i)}_1, X^{(i-1)}_3,...,X^{(i-1)}_j)$<br/>
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.<br/>
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.<br/>
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$X^{(i)}_j = f(X^{(i)}_j| X^{(i)}_1, X^{(i)}_2,...,X^{(i)}_{j-1})$<br/>
<br/>
izbrisi po?etnih $S$ uzoraka od $X_1...X_s$<br/>
iscrtaj ?eljene grafi?ke prikaze<br/>

****
#### Primeri:
****
1. Neka $\theta \sim N_2(0,\Sigma)$. Na?i aposteriornu ocenu parametra. Napomenimo da je 
\[
\Sigma = \left(\begin{array}{cc} 
1 & \rho\\
\rho & 1
\end{array}\right)
\]
matrica kovarijacije.

uslovne raspodele parametra $\theta_1$ i $\theta_2$ su:
\[ \theta_1|\theta_2 \sim N(\rho*\theta_2, 1-\rho^2) 
\]
\[i
\]
\[
  \theta_2|\theta_1 \sim N(\rho*\theta_1, 1-\rho^2)
\]




```{r echo=TRUE}
#inicijalizacija parametara uslovnih raspodela
ro <- 0.6
#S - koliko prvih elemenata odbacujemo
S <- 3000
#inic niza
teta1 <- teta2 <- rep(NA, 10000)
# incijalizacija pocetka (ne preterano bitna zbog prirode algoritma)
teta2[1] <- teta1[1] <- 1;

for(i in 2:10000){
  #uslovna f(teta1|teta2)
  teta1[i] <- rnorm(n = 1, mean = ro * teta2[i - 1], sd = 1 - ro * ro)
  #uslovna f(teta2|teta1)
  teta2[i] <- rnorm(n = 1, mean = ro * teta1[i], sd = 1 - ro * ro)
  #stampanje napretka
}
# odbacivanje pocetka
teta1 <- teta1[-(1:S)]
teta2 <- teta2[-(1:S)]

mean(teta1)
mean(teta2)

hist(teta1)
hist(teta2)

plot(teta1, teta2)
```


2. Neka $X \sim N(\mu, \frac{1}{\tau})$. Na?i aposteriornu ocenu parametra $\mu$ i $\tau$.

uslovne raspodele parametra $\mu$ i $\tau$ su:
\[
  \mu|\tau \sim N(\bar{x}, \frac{1}{n\tau})
\]
\[
i
\]
\[
  \tau|\mu \sim \gamma(\frac{n}{2},\frac{2}{(n-1)\sigma^2 + n(\mu-xs)^2})
\]

```{r echo=TRUE}
# statistike uzorka
# velicina uzorka
n <- 30
# o?ekivana srednja vrednost uzorka
xs <- 15
# o?ekivana disperzija uzorka
s2 <- 3

#inicijalizacija nizova
mu <- tau <- rep(NA, 10000)
# pocetni deo koji odbacujemo
S <- 3000
# incijalizacija
tau[1] <- 1
for(i in 2:10000) {
  #racunanje uslovne raspodele f(mu|tau)
  mu[i] <- rnorm(n = 1, mean = xs, sd = sqrt(1 / (n * tau[i - 1])))
  #f(tau|mu)
  tau[i] <- rgamma(n = 1, shape = n / 2, scale = 2 / ((n - 1) * s2 + n * (mu[i] - xs)^2))
}
# odbacivanje pocetaka
mu <- mu[-(1:S)]
tau <- tau[-(1:S)]

mean(mu)
mean(tau)

hist(mu)
hist(tau)

plot(mu, tau)
```



****
#### Primene
****


Algoritam generalno ne zavisi od problema i mo?e se primenjivati kad god imamo slo?ene raspodele iz kojih je te?ko uzorkovati, a naj?e??e primene su: <br/>
1. Ma?insko u?enje  - odre?ivanje raspodele radi predvi?anja re?i u tekstu jedna je od osnovnih primena, a one su u ovom polju veoma ?iroke. <br/>
2. Medicina ? nala?enje verovatno?e (gre?ke prve vrste) kod medicinskih testova. <br/>
3. Bioinformatika  - analiza genoma, biklasterovanje i nala?enje motiva u DNK i RNK danas su obe?avaju?e oblasti zahvaljuju?i ovom algoritmu. <br/>
4. Analiza podataka u prehrambrenoj industriji, trgovini nekretninama i naravno ekonomiji. <br/>

****
#### Mane
****


Iako mo?an, Gibsov algoritam ima 2 poznata slu?aja u kojima daje nepotpune rezultate: <br/>
1. Ukoliko su dva elementa vektora verovatno?a savr?eno korelisani ili anti-korelisani ementi, Gibsov algoritam bi?e zaglavljen i ne?e mo?i da ih promeni. <br/>
2. Ukoliko postoji sitno ostrvo stanja sa velikom verovatno?om nasuprot ve?ini ostalih sa zanemarljivim ili jako malim verovatno?ama, algoritam ?e izrazito dugo vra?ati stanja samo sa malom verovatno?om, pa zatim opet dugo sa velikom verovatno?om i bi?e mu potrebno oko $2^100$ iteracija da bi ispravno ocenio raspodelu.

****
#### Literatura
****

*OCENJIVANJE PARAMETARA ? BAJESOVSKI PRISTUP, Master rad, Sofija Suvo?arev, br. indeksa 1090/2010, Matemati?ki fakultet, str. 52-53, poglavlje 5.3 MCMC metod biranja uzorka.* <br/>
*Introduction to Mathematical Statistics, 6th edition, Hogg, McKean, Craig, poglavlje 11.4 Gibbs sampler*

****

Podatke objedinili za potrebe kursa Statitika na I smeru: <br/>
Nikola Mandi? 291/2015 <br/>
Aleksandar Jakovljevi? 156/2015 <br/>
